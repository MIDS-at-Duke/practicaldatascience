{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a Dask Cluster on AzureML\n",
    "\n",
    "In this lesson, we'll be using a dask cluster to replicate the [exercise we did in the Big Data section](exercises/Exercise_bigdata.ipynb) where we loaded global temperature data to measure global warming at a number of locations. You can get the data we're using for this [exercise here](https://www.dropbox.com/s/oq36w90hm9ltgvc/global_climate_data.zip?dl=0)).\n",
    "\n",
    "To run this code, in addition the `dask` and `pandas`, which you should already have installed, you'll need to install the following packages (`azureml-sdk` and `dask_cloudprovider`) with the following commands:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge azure-storage-blob # For managing storage\n",
    "pip install azureml-sdk                         # For managing compute\n",
    "pip install dask_cloudprovider=0.4.1\n",
    "```\n",
    "\n",
    "Note that `dask_cloudprovider` sometimes doesn't load the right version if you don't specify, and as of October 2020 the right version isn't even on `conda-forge`, so don't use `conda install`. You can also pip install `azure-storage-blob` if you prefer `pip` to `conda`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a Dask Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "from azureml.core import Workspace, Experiment\n",
    "from dask_cloudprovider import AzureMLCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm gonna load my subscription_id,\n",
    "# resource_group, and workspace_name from a hidden file\n",
    "# so y'all can't see them! You can just put in your code\n",
    "# if its private.\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"~/azure_secrets/azure_config.json\") as f:\n",
    "    account = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register workspace with account info\n",
    "ws = Workspace(\n",
    "    subscription_id=account[\"subscription_id\"],\n",
    "    resource_group=account[\"resource_group\"],\n",
    "    workspace_name=account[\"workspace_name\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING - If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................................................\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    }
   ],
   "source": [
    "# Start up a cluster!\n",
    "amlcluster = AzureMLCluster(\n",
    "    ws,\n",
    "    vm_size=\"STANDARD_DS13_V2\",  # Azure VM size for the Compute Target\n",
    "    environment_definition=ws.environments[\n",
    "        \"AzureML-Dask-CPU\"\n",
    "    ],  # Azure ML Environment to run on the cluster\n",
    "    jupyter=True,  # Flag to start JupyterLab session on the headnode\n",
    "    initial_node_count=2,  # number of nodes to start\n",
    "    scheduler_idle_timeout=7200,  # scheduler idle timeout in seconds\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04cf138d8eed417c85071d0001750761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>AzureMLCluster</h2>'), HBox(children=(HTML(value='\\n<div>\\n  <style scoped>\\n  â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "amlcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Your Cluster\n",
    "\n",
    "There are two ways to use your cluster: You can click on the link above to open a connection to JupyterLab running on one of the computers in your cluster, or connect from here with this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Nick/miniconda3/lib/python3.7/site-packages/distributed/client.py:1130: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+---------------+---------------+---------------+\n",
      "| Package | client        | scheduler     | workers       |\n",
      "+---------+---------------+---------------+---------------+\n",
      "| lz4     | None          | 3.1.0         | 3.1.0         |\n",
      "| numpy   | 1.19.1        | 1.19.2        | 1.19.2        |\n",
      "| python  | 3.7.8.final.0 | 3.6.9.final.0 | 3.6.9.final.0 |\n",
      "+---------+---------------+---------------+---------------+\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n",
      "WARNING - Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa21553c490>: Failed to establish a new connection: [Errno 60] Operation timed out')': /history/v1.0/subscriptions/bab5ec70-4531-48dc-9d25-2d73206d5741/resourceGroups/nce8rg/providers/Microsoft.MachineLearningServices/workspaces/nce8ws/experiments/dask-cloudprovider/runs/dask-cloudprovider_1602169849_0bddc1d9\n",
      "WARNING - Retrying (Retry(total=2, connect=2, read=3, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7fa215508b50>: Failed to establish a new connection: [Errno 60] Operation timed out')': /history/v1.0/subscriptions/bab5ec70-4531-48dc-9d25-2d73206d5741/resourceGroups/nce8rg/providers/Microsoft.MachineLearningServices/workspaces/nce8ws/experiments/dask-cloudprovider/runs/dask-cloudprovider_1602169849_0bddc1d9\n",
      "WARNING - Retrying (Retry(total=2, connect=3, read=2, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', TimeoutError(60, 'Operation timed out'))': /history/v1.0/subscriptions/bab5ec70-4531-48dc-9d25-2d73206d5741/resourceGroups/nce8rg/providers/Microsoft.MachineLearningServices/workspaces/nce8ws/experiments/dask-cloudprovider/runs/dask-cloudprovider_1602169849_0bddc1d9\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "c = Client(amlcluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you're off to the races!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data from Azure\n",
    "\n",
    "If your data is CSV or parquet... \n",
    "\n",
    "Load `adlfs`:\n",
    "\n",
    "```\n",
    "conda install -c conda-forge adlfs\n",
    "```\n",
    "\n",
    "Then just put your account data in a dictionary, put `az` at start of reads, and use the `storage_options`. \n",
    "\n",
    "```\n",
    "import dask.dataframe as dd\n",
    "\n",
    "storage_options={'account_name': ACCOUNT_NAME, 'account_key': ACCOUNT_KEY}\n",
    "\n",
    "ddf = dd.read_csv('az://{CONTAINER}/{FOLDER}/*.csv', storage_options=storage_options)\n",
    "ddf = dd.read_parquet('az://{CONTAINER}/folder.parquet', storage_options=storage_options)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
